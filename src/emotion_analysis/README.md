# 情感分析模块
## 1. 模块介绍
### 1.1 模块功能
情感分析模块主要实现了对提取到的文本的情感分析，包括使用的情感分析算法有：基于词典的情感分析、基于SO-PMI的情感分析、基于TextCNN的情感分析。

### 1.2 模块目录结构
```
│  
├─ README.md
├─ lexicon_weighted
│      LWS.py
├─ SO_PMI
│      SO_PMI_cal.py
│      SO_PMI_prepare.py
│      SO_PMI_train.py
└─ TextCNN
        TextCNN_cal.py
        TextCNN_train.py
```

## 2. Lexicon-based情感分析

### 2.1 工作流程

这段代码定义了一个基于词典的情感分析类，名为 `LexiconWeightedSentiment`，用于分析文本（主要是评论）的情感倾向。代码的工作流程可以分为以下几个主要部分：

1. **初始化和加载词典**：在 `LexiconWeightedSentiment` 类的初始化过程中，首先调用 `load_dictionaries` 方法来加载各种词典。这些词典包括程度词（如“非常”，“稍微”等）和情感词（分为正面和负面），以及中英文停用词。这些词典的路径被定义在一个字典结构中，每个路径对应不同类型的词典文件。加载这些词典是为了后续在文本分析中能够识别并正确处理这些关键词。

2. **词典处理**：加载词典后，对程度词进行特别处理，将它们按照程度分类（如“最”、“很”、“较”、“略”、“不足”、“过”等类别），为之后的情感分析打基础。同时，将中英文的负面和正面情感词汇合并，形成两个大的情感词列表。

3. **文本预处理**：在文本分析前，需要对文本进行预处理。这包括使用 `jieba` 分词库进行中文分词（`word_cut` 方法），以及移除停用词（`remove_stopwords` 方法）。停用词是指那些在文本分析中通常被忽略的词汇，如“的”、“了”等。

4. **情感评分**：`score` 方法是核心部分，它根据分词后的文本计算情感得分。这一过程涉及到检查每个词是否是情感词（正面或负面），以及它前面是否有程度词，来决定这个词的情感强度。例如，一个负面情感词前面如果有一个表示“最高程度”的词，它的负面影响就会被放大。最后，将所有词的情感得分相加，得到整个文本的情感得分。

5. **情感分析**：`analyze_sentiment_score` 方法接收一组评论，对每条评论进行上述情感评分的处理，并返回每条评论的情感得分。

6. **实际应用**：在代码的最后部分，通过实例化 `LexiconWeightedSentiment` 类并调用 `analyze_sentiment_score` 方法，对一个评论集合进行情感分析。之后，根据得分将评论分类为正面、负面或中性，并输出每类评论的数量。


## 3. SO-PMI情感分析

### 3.1 字典构建与训练

`src\emotion_analysis\SO_PMI\SO_PMI_train.py` 代码实现了一个名为 `SoPmi` 的类，目的是利用小型词典和大量语言数据训练出一个具有高相关性的大型词典。这个过程主要通过计算词语之间的语义关联（即点互信息，PMI）来完成。代码的工作流程可以分为几个主要步骤：

1. **初始化和文件路径设置**：在 `SoPmi` 类的初始化方法中，定义了几个关键文件的路径，包括训练数据集、候选正面词典、候选负面词典和情感词典的路径。这些文件是后续步骤中数据处理和分析的基础。其中初始的小型情感词典是由人工标注的，统计了大量评论中出现频率较高的词语，并根据其情感倾向（正面或负面）进行了标注，得到一个大小为 80 的情感词典。

2. **分词处理**：`seg_corpus` 方法用于对训练数据集进行分词处理。首先，它从情感词典中读取情感词并将它们添加到 `jieba` 分词库中，以确保这些情感词被正确分词。然后，对每行文本进行分词，排除一些特定词性的词（如助词、标点符号等），以便得到更纯净的数据。

3. **搭配次数统计**：`collect_cowords` 方法统计词语之间的共现次数。这个方法首先定义了一个窗口大小，用于确定在每个词周围考虑多远的距离内的词。然后，它遍历每个句子中的词，收集在窗口大小范围内共现的词对。这些词对将用于计算点互信息（PMI）。

4. **So-Pmi值计算**：`collect_candiwords` 方法是整个过程中最关键的部分。这个方法首先统计了分词后文本中各词的出现频率，以及词对的共现次数。接着，它使用这些数据计算每个候选词与情感词（正面和负面）之间的点互信息（PMI）。计算得到的 So-Pmi 值反映了候选词与正负情感词的相关性。

5. **结果保存**：`save_candiwords` 方法用于将计算得到的 So-Pmi 值保存到文件中。这个方法会根据 So-Pmi 值的正负将词分为正面和负面两类，并保存到相应的文件中。

6. **主方法**：在类的最后，`sopmi` 方法将上述步骤串联起来，形成一个完整的流程。这个方法首先对训练数据进行分词处理，然后收集词对共现次数，计算 So-Pmi 值，并将结果保存到文件中。

总体而言，这段代码通过从大量文本数据中挖掘词语的共现关系，并计算它们与已知情感词的点互信息，从而能够识别出与情感高度相关的词汇。这个过程不仅可以扩展现有的情感词典，还能增强情感分析的准确性和覆盖范围。

### 3.2 情感分析

`src\emotion_analysis\SO_PMI\SO_PMI_cal.py` 代码实现了一个名为 `SoPmiSentiment` 的类，用于利用基于 SoPmi 方法训练出的词典进行情感分析。工作流程可以分为以下几个主要步骤：

1. **初始化和加载词典**：
在类的初始化过程中，首先调用 `load_dictionaries` 方法来加载几个关键的词典：正面情感词典、负面情感词典、否定词典和程度副词词典。词典中的每个词都被赋予一个权重。对于情感词典中的词，权重是根据其在词典中的位置来决定的，位置越靠前，权重越大。权重体现了该词在表示情感时的强度。否定词和程度副词也被加载到相应的字典中，这些词在计算情感分数时会被用来修改情感词的强度。

2. **分词处理**：
  `word_cut` 方法使用 `jieba` 分词库对文本进行分词。

3. **情感评分计算**：
`score` 方法是情感分析的核心。它首先过滤掉那些不在三个词典（情感词、否定词、程度副词）中的词，然后遍历每个词进行情感分数的计算。对于每个情感词，方法会考虑它前面的否定词和程度副词来调整其情感强度。如果存在否定词，情感分数会反转；如果存在程度副词，情感分数会相应增强或减弱。最后，所有情感词的分数累加起来得到整个句子的情感分数。

4. **情感分析应用**：
在主函数中，首先从文件中读取评论数据，然后实例化 `SoPmiSentiment` 类。对每条评论进行分词，然后调用 `score` 方法计算情感分数。根据情感分数将评论分类为正面、负面或中性，并输出每类评论的数量。

总体而言，这段代码通过结合情感词典、否定词和程度副词来计算文本的情感倾向。

## 4. TextCNN情感分析

### 4.1 模型训练

`src\emotion_analysis\TextCNN\TextCNN_train.py` 代码实现了一个基于卷积神经网络（CNN）的文本分类模型，名为 TextCNN，用于情感分析。整个过程从数据预处理开始，首先读取标有标签的评论数据，然后对这些评论进行分词处理，统计每条评论的词数，并进行基本的数据分析。为了过滤出高频词汇，设置了一个频率阈值，并建立了一个词汇表，其中只包含出现频率高于该阈值的词。每个词汇都被赋予了一个唯一的索引，以便在后续的处理中使用。

预处理的下一步涉及将评论转换为索引表示形式。这里的目标是将每条评论转换为相同长度的数字序列，以便它们可以被模型处理。长度较短的评论通过添加特定的填充词（在这种情况下是中文词“把”）来扩展到所需长度。这一步是为了确保所有输入数据都具有一致的维度，这是深度学习模型所要求的。

接下来，代码加载了预训练的 Word2Vec 词向量模型。该模型将每个词汇映射到一个固定大小的向量空间中，这些向量能够捕捉词汇之间的语义关系。对于词汇表中的每个词，代码尝试从 Word2Vec 模型中获取其向量表示。如果某个词不在 Word2Vec 模型中，则为其随机生成一个向量。这样，每个词都有了一个确定的向量表示，无论它是否出现在预训练模型中。

在模型定义阶段，TextCNN 使用卷积层来提取文本特征。卷积操作能够捕捉到文本中的局部特征，这对于理解文本的语义内容非常重要。卷积层后是池化层，用于降低特征维度并提取最重要的特征。最后，通过一个全连接层将这些特征映射到输出类别上，并使用 softmax 函数来计算最终的分类概率。

训练过程中，使用 Adam 优化器和负对数似然损失函数来优化模型参数。数据集被分为训练集、验证集和测试集，训练过程中使用 DataLoader 进行批量加载和打乱数据。在每个训练周期内，模型对训练集的每批数据进行学习，通过反向传播算法调整网络参数以最小化损失函数。同时，记录每个批次的训练准确率，并计算整个训练集的平均准确率。

训练完成后，模型在测试集上进行评估，计算其准确率。此外，还绘制了训练准确率的变化曲线，以可视化模型训练过程中准确率的变化情况。最后，模型的参数被保存下来，以便未来的使用或进一步的分析。通过这个过程，TextCNN 模型能够有效地从文本数据中学习和提取有用的特征，进行准确的情感分类。

### 4.2 情感分析

`src\emotion_analysis\TextCNN\TextCNN_cal.py` 这段代码展示了如何使用预先训练好的 TextCNN 模型进行文本数据的情感分析。整个过程开始于词汇表和词向量的准备阶段。在这个阶段，首先从一个文本文件中读取词汇表，这个词汇表包含了训练期间使用的所有词汇。然后，利用预先训练的 Word2Vec 模型为这些词汇生成词向量。这种词向量表示法能够捕捉词汇之间的丰富语义关系。对于那些不存在于 Word2Vec 模型中的词汇，代码会随机生成一个向量，以确保每个词都有一个独特的向量表示。

接下来，定义了 TextCNN 模型的架构。这个模型包含一个卷积层、一个池化层和一个全连接层。卷积层在处理文本时可以捕捉局部特征，而池化层则用于降低特征的维度，从而减少模型的计算量。全连接层最后将这些特征映射到分类输出上。此外，模型还包括 Dropout 层，以防止过拟合并增强模型的泛化能力。

在预测阶段，首先对输入文本进行预处理。这个预处理包括将文本分词并将每个词转换为其在词汇表中的索引。如果文本中的某个词不在词汇表中，则使用一个特定的填充词代替。为了保证模型输入的一致性，对于长度不足的文本会进行填充，而过长的文本则会被截断。随后，加载之前训练好的 TextCNN 模型，并将其设置为评估模式。这意味着模型在预测时不会使用训练阶段的某些特定操作，如 Dropout。

在执行预测时，将处理过的文本数据转换为模型可以接受的格式，然后输入到模型中。模型输出每个类别的概率，从中选择概率最高的类别作为预测结果。通过这种方式，可以将每条评论分类为正面、负面或中性。最后，代码汇总并输出了正面评论、负面评论和中性评论的数量，为分析整体情感倾向提供了一种直观的方式。

整体来看，这个过程通过结合先进的词嵌入技术和卷积神经网络的强大特征提取能力，有效地对文本数据进行了情感分析。它不仅能够理解词汇之间的复杂关系，还能够捕捉文本中的关键信息，使得情感分类既准确又高效。

### 4.3 存在问题

1. **有限的标注数据集**：
   
高质量的标注数据集对于训练任何监督学习模型至关重要。这些数据提供了必要的信息，使模型能够学习如何从输入数据中准确地识别出所需的模式或特征。

由于没有找到标注正面、负面、中性情感的影评集合，只找到标注了正面和负面的数据集，并且数量有限，因此在训练 TextCNN 模型时，只使用了这些数据集中的一部分数据。这可能会影响模型的性能，因为模型无法从有限的数据中学习到足够多的特征。

同时由于使用了 Word2Vec 词向量模型，对于词汇表中不存在的词，使用了随机生成的向量，这可能会影响模型的性能，因为这些词的向量表示可能无法捕捉到它们的语义信息。

1. **计算资源的限制**：

神经网络模型，尤其是深度学习模型，通常需要大量的计算资源进行训练。这包括高性能的 GPU 和大量的内存资源。

由于没有足够的计算资源，并且使用CPU而非GPU进行训练，因此在训练 TextCNN 模型时，只使用了较小的词汇表和较短的评论长度。这可能会影响模型的性能，因为模型无法从更大的词汇表和更长的评论中学习到更多的特征。这会导致模型的准确率较低。
